{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.10.12","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"gpu","dataSources":[{"sourceId":7035994,"sourceType":"datasetVersion","datasetId":4047779},{"sourceId":7038816,"sourceType":"datasetVersion","datasetId":4049634},{"sourceId":7041418,"sourceType":"datasetVersion","datasetId":4051250}],"dockerImageVersionId":30580,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":true}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"markdown","source":"Training was done in **kuggle**","metadata":{}},{"cell_type":"markdown","source":"### Preparation","metadata":{}},{"cell_type":"code","source":"import torch\nfrom tqdm.notebook import tqdm\n\nimport pandas as pd\n\nfrom torch.utils.data import Dataset, DataLoader\nfrom sklearn.metrics import classification_report, accuracy_score, f1_score\nfrom transformers import (set_seed,\n                          TrainingArguments,\n                          Trainer,\n                          GPT2Config,\n                          AutoTokenizer,\n                          GPT2Tokenizer,\n                          AdamW, \n                          get_cosine_schedule_with_warmup,\n                          GPT2ForSequenceClassification, \n                          T5ForConditionalGeneration)\n\nepochs = 4\nbatch_size = 8\nmax_length = 612\n\ndevice = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n\nmodel_name_or_path = 'ai-forever/rugpt3small_based_on_gpt2'","metadata":{"execution":{"iopub.status.busy":"2023-11-24T07:49:13.599308Z","iopub.execute_input":"2023-11-24T07:49:13.599606Z","iopub.status.idle":"2023-11-24T07:49:30.834831Z","shell.execute_reply.started":"2023-11-24T07:49:13.599578Z","shell.execute_reply":"2023-11-24T07:49:30.834039Z"},"trusted":true},"execution_count":1,"outputs":[{"name":"stderr","text":"/opt/conda/lib/python3.10/site-packages/scipy/__init__.py:146: UserWarning: A NumPy version >=1.16.5 and <1.23.0 is required for this version of SciPy (detected version 1.24.3\n  warnings.warn(f\"A NumPy version >={np_minversion} and <{np_maxversion}\"\n","output_type":"stream"}]},{"cell_type":"code","source":"df = pd.read_csv('/kaggle/input/hackathon/train_dataset_train.csv', sep=';')\ndf.head()","metadata":{"execution":{"iopub.status.busy":"2023-11-24T07:49:30.836665Z","iopub.execute_input":"2023-11-24T07:49:30.837434Z","iopub.status.idle":"2023-11-24T07:49:31.294665Z","shell.execute_reply.started":"2023-11-24T07:49:30.837398Z","shell.execute_reply":"2023-11-24T07:49:31.293830Z"},"trusted":true},"execution_count":2,"outputs":[{"execution_count":2,"output_type":"execute_result","data":{"text/plain":"                            Исполнитель                        Группа тем  \\\n0           Лысьвенский городской округ                   Благоустройство   \n1  Министерство социального развития ПК  Социальное обслуживание и защита   \n2  Министерство социального развития ПК  Социальное обслуживание и защита   \n3                           Город Пермь            Общественный транспорт   \n4          Министерство здравоохранения          Здравоохранение/Медицина   \n\n                                     Текст инцидента  \\\n0  'Добрый день. Сегодня, 20.08.22, моя мать шла ...   \n1  'Пермь г, +79194692145. В Перми с ноября 2021 ...   \n2  'Добрый день ! Скажите пожалуйста если подовал...   \n3  'Каждая из них не о чем. Люди на остановках хо...   \n4  'В Березниках у сына привитого откоронавируса ...   \n\n                                              Тема  \n0                                  ★ Ямы во дворах  \n1                        Оказание гос. соц. помощи  \n2                         Дети и многодетные семьи  \n3                             Содержание остановок  \n4  Технические проблемы с записью на прием к врачу  ","text/html":"<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>Исполнитель</th>\n      <th>Группа тем</th>\n      <th>Текст инцидента</th>\n      <th>Тема</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>Лысьвенский городской округ</td>\n      <td>Благоустройство</td>\n      <td>'Добрый день. Сегодня, 20.08.22, моя мать шла ...</td>\n      <td>★ Ямы во дворах</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>Министерство социального развития ПК</td>\n      <td>Социальное обслуживание и защита</td>\n      <td>'Пермь г, +79194692145. В Перми с ноября 2021 ...</td>\n      <td>Оказание гос. соц. помощи</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>Министерство социального развития ПК</td>\n      <td>Социальное обслуживание и защита</td>\n      <td>'Добрый день ! Скажите пожалуйста если подовал...</td>\n      <td>Дети и многодетные семьи</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>Город Пермь</td>\n      <td>Общественный транспорт</td>\n      <td>'Каждая из них не о чем. Люди на остановках хо...</td>\n      <td>Содержание остановок</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>Министерство здравоохранения</td>\n      <td>Здравоохранение/Медицина</td>\n      <td>'В Березниках у сына привитого откоронавируса ...</td>\n      <td>Технические проблемы с записью на прием к врачу</td>\n    </tr>\n  </tbody>\n</table>\n</div>"},"metadata":{}}]},{"cell_type":"code","source":"# renaming columns\ndf[\"text\"] = df[\"Группа тем\"] + ': ' + df[\"Текст инцидента\"]\ndf = df[['text', 'Тема']]\ndf = df.dropna()\ndf.columns = ['text', 'label']\ndf.head()","metadata":{"execution":{"iopub.status.busy":"2023-11-24T07:49:31.295718Z","iopub.execute_input":"2023-11-24T07:49:31.296013Z","iopub.status.idle":"2023-11-24T07:49:31.342092Z","shell.execute_reply.started":"2023-11-24T07:49:31.295989Z","shell.execute_reply":"2023-11-24T07:49:31.341228Z"},"trusted":true},"execution_count":3,"outputs":[{"execution_count":3,"output_type":"execute_result","data":{"text/plain":"                                                text  \\\n0  Благоустройство: 'Добрый день. Сегодня, 20.08....   \n1  Социальное обслуживание и защита: 'Пермь г, +7...   \n2  Социальное обслуживание и защита: 'Добрый день...   \n3  Общественный транспорт: 'Каждая из них не о че...   \n4  Здравоохранение/Медицина: 'В Березниках у сына...   \n\n                                             label  \n0                                  ★ Ямы во дворах  \n1                        Оказание гос. соц. помощи  \n2                         Дети и многодетные семьи  \n3                             Содержание остановок  \n4  Технические проблемы с записью на прием к врачу  ","text/html":"<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>text</th>\n      <th>label</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>Благоустройство: 'Добрый день. Сегодня, 20.08....</td>\n      <td>★ Ямы во дворах</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>Социальное обслуживание и защита: 'Пермь г, +7...</td>\n      <td>Оказание гос. соц. помощи</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>Социальное обслуживание и защита: 'Добрый день...</td>\n      <td>Дети и многодетные семьи</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>Общественный транспорт: 'Каждая из них не о че...</td>\n      <td>Содержание остановок</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>Здравоохранение/Медицина: 'В Березниках у сына...</td>\n      <td>Технические проблемы с записью на прием к врачу</td>\n    </tr>\n  </tbody>\n</table>\n</div>"},"metadata":{}}]},{"cell_type":"code","source":"labels = list(df.label.unique())\nlabel2id = dict(zip(labels, list(range(len(labels)))))\nn_labels = len(label2id)","metadata":{"execution":{"iopub.status.busy":"2023-11-24T07:49:31.343941Z","iopub.execute_input":"2023-11-24T07:49:31.344225Z","iopub.status.idle":"2023-11-24T07:49:31.355491Z","shell.execute_reply.started":"2023-11-24T07:49:31.344200Z","shell.execute_reply":"2023-11-24T07:49:31.354672Z"},"trusted":true},"execution_count":4,"outputs":[]},{"cell_type":"code","source":"class MyDataset(Dataset):\n    def __init__(self, df, tokenizer):\n        self.n_examples = df.shape[0]\n        self.texts = df['text'].to_list()\n        self.labels = df['label'].to_list()\n  \n    def __len__(self):\n        return self.n_examples\n\n    def __getitem__(self, item):\n        return {'text':self.texts[item], 'label':self.labels[item]}","metadata":{"execution":{"iopub.status.busy":"2023-11-24T07:49:31.356581Z","iopub.execute_input":"2023-11-24T07:49:31.356919Z","iopub.status.idle":"2023-11-24T07:49:31.363048Z","shell.execute_reply.started":"2023-11-24T07:49:31.356869Z","shell.execute_reply":"2023-11-24T07:49:31.362194Z"},"trusted":true},"execution_count":5,"outputs":[]},{"cell_type":"code","source":"class Gpt2ClassificationCollator(object):\n    def __init__(self, tokenizer, labels_encoder, max_sequence_len=None):\n            self.use_tokenizer = tokenizer\n            self.max_sequence_len = tokenizer.model_max_length if max_sequence_len is None else max_sequence_len\n            self.labels_encoder = labels_encoder\n\n\n    def __call__(self, sequences):\n        # Get all texts from sequences list.\n        texts = [sequence['text'] for sequence in sequences]\n        # Get all labels from sequences list.\n        labels = [sequence['label'] for sequence in sequences]\n        # Encode all labels using label encoder.\n        labels = [self.labels_encoder[label] for label in labels]\n        # Call tokenizer on all texts to convert into tensors of numbers with \n        # appropriate padding.\n        inputs = self.use_tokenizer(text=texts, return_tensors=\"pt\", padding=True, truncation=True,  max_length=self.max_sequence_len)\n        # Update the inputs with the associated encoded labels as tensor.\n        inputs.update({'labels':torch.tensor(labels)})\n\n        return inputs","metadata":{"execution":{"iopub.status.busy":"2023-11-24T07:49:31.364244Z","iopub.execute_input":"2023-11-24T07:49:31.365021Z","iopub.status.idle":"2023-11-24T07:49:31.374113Z","shell.execute_reply.started":"2023-11-24T07:49:31.364989Z","shell.execute_reply":"2023-11-24T07:49:31.373293Z"},"trusted":true},"execution_count":6,"outputs":[]},{"cell_type":"code","source":"from torch.nn import CrossEntropyLoss\n\ndef train(dataloader, optimizer_, scheduler_, device_):\n    global model\n\n    predictions_labels = []\n    true_labels = []\n    total_loss = 0\n    \n    loss_fn = CrossEntropyLoss()\n\n    model.train()\n\n    for batch in tqdm(dataloader, total=len(dataloader)):\n\n        true_labels += batch['labels'].numpy().flatten().tolist()\n\n        batch = {k:v.type(torch.long).to(device_) for k,v in batch.items()}\n\n        model.zero_grad()\n\n        outputs = model(**batch)\n\n        loss, logits = outputs[:2]\n\n        total_loss += loss.item()\n\n        loss.backward()\n\n        torch.nn.utils.clip_grad_norm_(model.parameters(), 1.0)\n\n        optimizer_.step()\n\n        scheduler_.step()\n\n        logits = logits.detach().cpu().numpy()\n\n        predictions_labels += logits.argmax(axis=-1).flatten().tolist()\n\n    avg_epoch_loss = total_loss / len(dataloader)\n\n    return true_labels, predictions_labels, avg_epoch_loss","metadata":{"execution":{"iopub.status.busy":"2023-11-24T07:49:31.375151Z","iopub.execute_input":"2023-11-24T07:49:31.375405Z","iopub.status.idle":"2023-11-24T07:49:31.388451Z","shell.execute_reply.started":"2023-11-24T07:49:31.375382Z","shell.execute_reply":"2023-11-24T07:49:31.387608Z"},"trusted":true},"execution_count":7,"outputs":[]},{"cell_type":"code","source":"def validation(dataloader, device_):\n    global model\n\n    predictions_labels = []\n    true_labels = []\n    total_loss = 0\n\n    model.eval()\n\n    for batch in tqdm(dataloader, total=len(dataloader)):\n\n        true_labels += batch['labels'].numpy().flatten().tolist()\n\n        batch = {k:v.type(torch.long).to(device_) for k,v in batch.items()}\n\n        with torch.no_grad():        \n\n            outputs = model(**batch)\n\n            loss, logits = outputs[:2]\n\n            logits = logits.detach().cpu().numpy()\n\n            total_loss += loss.item()\n\n            predict_content = logits.argmax(axis=-1).flatten().tolist()\n\n            predictions_labels += predict_content\n\n    avg_epoch_loss = total_loss / len(dataloader)\n\n    return true_labels, predictions_labels, avg_epoch_loss","metadata":{"execution":{"iopub.status.busy":"2023-11-24T07:49:31.389480Z","iopub.execute_input":"2023-11-24T07:49:31.389777Z","iopub.status.idle":"2023-11-24T07:49:31.403177Z","shell.execute_reply.started":"2023-11-24T07:49:31.389745Z","shell.execute_reply":"2023-11-24T07:49:31.402297Z"},"trusted":true},"execution_count":8,"outputs":[]},{"cell_type":"markdown","source":"### Training","metadata":{}},{"cell_type":"code","source":"print('Loading configuraiton...')\nmodel_config = GPT2Config.from_pretrained(pretrained_model_name_or_path=model_name_or_path, num_labels=n_labels)\n\nprint('Loading tokenizer...')\ntokenizer = GPT2Tokenizer.from_pretrained(pretrained_model_name_or_path=model_name_or_path)\ntokenizer.padding_side = \"left\"\ntokenizer.pad_token = tokenizer.eos_token\n\nprint('Loading model...')\nmodel = GPT2ForSequenceClassification.from_pretrained(pretrained_model_name_or_path=model_name_or_path, config=model_config)\n\nmodel.resize_token_embeddings(len(tokenizer))\nmodel.config.pad_token_id = model.config.eos_token_id\n\nmodel.to(device)\nprint('Model loaded to `%s`'%device)","metadata":{"execution":{"iopub.status.busy":"2023-11-24T07:49:31.404274Z","iopub.execute_input":"2023-11-24T07:49:31.404501Z","iopub.status.idle":"2023-11-24T07:49:42.246171Z","shell.execute_reply.started":"2023-11-24T07:49:31.404481Z","shell.execute_reply":"2023-11-24T07:49:42.244884Z"},"trusted":true},"execution_count":9,"outputs":[{"name":"stdout","text":"Loading configuraiton...\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"Downloading config.json:   0%|          | 0.00/608 [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"45f8b7007d7a43209011c2be5afb7330"}},"metadata":{}},{"name":"stdout","text":"Loading tokenizer...\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"Downloading vocab.json:   0%|          | 0.00/1.71M [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"73b830ce386c4c66bbd738a8c9e883a8"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Downloading merges.txt:   0%|          | 0.00/1.27M [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"c272fecc9c9f4a93bdc961b390f9231c"}},"metadata":{}},{"name":"stdout","text":"Loading model...\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"Downloading pytorch_model.bin:   0%|          | 0.00/551M [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"7e73f5b0640f4ea881580a9f7b028306"}},"metadata":{}},{"name":"stderr","text":"Some weights of GPT2ForSequenceClassification were not initialized from the model checkpoint at ai-forever/rugpt3small_based_on_gpt2 and are newly initialized: ['score.weight']\nYou should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n","output_type":"stream"},{"name":"stdout","text":"Model loaded to `cuda`\n","output_type":"stream"}]},{"cell_type":"markdown","source":"#### Training with original data","metadata":{}},{"cell_type":"code","source":"from sklearn.model_selection import train_test_split\n\nX_train, X_val, y_train, y_val = train_test_split(df[\"text\"], df[\"label\"], test_size=0.2, random_state=42, \n                                                    stratify=df[\"label\"], shuffle=True)","metadata":{"execution":{"iopub.status.busy":"2023-11-24T07:49:42.250412Z","iopub.execute_input":"2023-11-24T07:49:42.250935Z","iopub.status.idle":"2023-11-24T07:49:42.325710Z","shell.execute_reply.started":"2023-11-24T07:49:42.250897Z","shell.execute_reply":"2023-11-24T07:49:42.324771Z"},"trusted":true},"execution_count":10,"outputs":[{"name":"stderr","text":"/opt/conda/lib/python3.10/site-packages/sklearn/utils/validation.py:605: FutureWarning: is_sparse is deprecated and will be removed in a future version. Check `isinstance(dtype, pd.SparseDtype)` instead.\n  if is_sparse(pd_dtype):\n/opt/conda/lib/python3.10/site-packages/sklearn/utils/validation.py:614: FutureWarning: is_sparse is deprecated and will be removed in a future version. Check `isinstance(dtype, pd.SparseDtype)` instead.\n  if is_sparse(pd_dtype) or not is_extension_array_dtype(pd_dtype):\n","output_type":"stream"}]},{"cell_type":"code","source":"df_train = pd.DataFrame(data={\n    \"text\": X_train,\n    \"label\": y_train\n})\n\ndf_val = pd.DataFrame(data={\n    \"text\": X_val,\n    \"label\": y_val\n})","metadata":{"execution":{"iopub.status.busy":"2023-11-24T07:49:42.327075Z","iopub.execute_input":"2023-11-24T07:49:42.327464Z","iopub.status.idle":"2023-11-24T07:49:42.334027Z","shell.execute_reply.started":"2023-11-24T07:49:42.327427Z","shell.execute_reply":"2023-11-24T07:49:42.333058Z"},"trusted":true},"execution_count":11,"outputs":[]},{"cell_type":"code","source":"gpt2_classificaiton_collator = Gpt2ClassificationCollator(tokenizer=tokenizer, \n                                                          labels_encoder=label2id, \n                                                          max_sequence_len=max_length)\n\n\nprint('Dealing with Train...')\ntrain_dataset = MyDataset(df=df_train, \n                               tokenizer=tokenizer)\nprint('Created `train_dataset` with %d examples!'%len(train_dataset))\n\ntrain_dataloader = DataLoader(train_dataset, batch_size=batch_size, shuffle=True, collate_fn=gpt2_classificaiton_collator)\nprint('Created `train_dataloader` with %d batches!'%len(train_dataloader))\n\nprint()","metadata":{"execution":{"iopub.status.busy":"2023-11-24T07:49:42.335189Z","iopub.execute_input":"2023-11-24T07:49:42.335449Z","iopub.status.idle":"2023-11-24T07:49:42.346105Z","shell.execute_reply.started":"2023-11-24T07:49:42.335426Z","shell.execute_reply":"2023-11-24T07:49:42.345206Z"},"trusted":true},"execution_count":12,"outputs":[{"name":"stdout","text":"Dealing with Train...\nCreated `train_dataset` with 18502 examples!\nCreated `train_dataloader` with 2313 batches!\n\n","output_type":"stream"}]},{"cell_type":"code","source":"print('Dealing with Validation...')\nvalid_dataset =  MyDataset(df=df_val, \n                               tokenizer=tokenizer)\nprint('Created `valid_dataset` with %d examples!'%len(valid_dataset))\n\nvalid_dataloader = DataLoader(valid_dataset, batch_size=batch_size, shuffle=False, collate_fn=gpt2_classificaiton_collator)\nprint('Created `eval_dataloader` with %d batches!'%len(valid_dataloader))","metadata":{"execution":{"iopub.status.busy":"2023-11-24T07:49:42.347379Z","iopub.execute_input":"2023-11-24T07:49:42.347745Z","iopub.status.idle":"2023-11-24T07:49:42.357491Z","shell.execute_reply.started":"2023-11-24T07:49:42.347709Z","shell.execute_reply":"2023-11-24T07:49:42.356510Z"},"trusted":true},"execution_count":13,"outputs":[{"name":"stdout","text":"Dealing with Validation...\nCreated `valid_dataset` with 4626 examples!\nCreated `eval_dataloader` with 579 batches!\n","output_type":"stream"}]},{"cell_type":"code","source":"from sklearn.metrics import classification_report, accuracy_score, f1_score\nfrom transformers import Adafactor\n\noptimizer = Adafactor(model.parameters(),\n                  lr = 2e-3,\n                  relative_step=False)\n\ntotal_steps = len(train_dataloader) * epochs\n\nscheduler = get_cosine_schedule_with_warmup(optimizer, \n                                            num_warmup_steps = 0,\n                                            num_training_steps = total_steps)\nprint('Epoch')\nfor epoch in tqdm(range(epochs)):\n    print()\n    print('Training on batches...')\n\n    train_labels, train_predict, train_loss = train(train_dataloader, optimizer, scheduler, device)\n    train_f1 = f1_score(train_labels, train_predict, average='weighted')\n\n\n    print('Validation on batches...')\n    valid_labels, valid_predict, val_loss = validation(valid_dataloader, device)\n    val_f1 = f1_score(valid_labels, valid_predict, average='weighted')\n\n    print(\"train_loss: %.5f - val_loss: %.5f - train_f1: %.5f - val_f1: %.5f\"%(train_loss, val_loss, train_f1, val_f1))\n    print()","metadata":{"execution":{"iopub.status.busy":"2023-11-24T07:49:42.358609Z","iopub.execute_input":"2023-11-24T07:49:42.358940Z","iopub.status.idle":"2023-11-24T08:25:16.809815Z","shell.execute_reply.started":"2023-11-24T07:49:42.358893Z","shell.execute_reply":"2023-11-24T08:25:16.808976Z"},"trusted":true},"execution_count":14,"outputs":[{"name":"stdout","text":"Epoch\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"  0%|          | 0/4 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"9df1c6de98ba4d288bd831246236d0b8"}},"metadata":{}},{"name":"stdout","text":"\nTraining on batches...\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"  0%|          | 0/2313 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"374b44c474fb4fb2a27b3e1906a28f15"}},"metadata":{}},{"name":"stdout","text":"Validation on batches...\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"  0%|          | 0/579 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"33d9bcdd50bc4af3b4cce258164ec75a"}},"metadata":{}},{"name":"stdout","text":"train_loss: 1.96687 - val_loss: 1.47415 - train_f1: 0.41666 - val_f1: 0.50372\n\n\nTraining on batches...\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"  0%|          | 0/2313 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"05f3755ec73049529ddf463325cf4725"}},"metadata":{}},{"name":"stdout","text":"Validation on batches...\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"  0%|          | 0/579 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"13b4761a953f4503a34eff443b41620b"}},"metadata":{}},{"name":"stdout","text":"train_loss: 1.19662 - val_loss: 1.19754 - train_f1: 0.60193 - val_f1: 0.59954\n\n\nTraining on batches...\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"  0%|          | 0/2313 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"d75244bf28f44204ad5fa8dc5e33b800"}},"metadata":{}},{"name":"stdout","text":"Validation on batches...\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"  0%|          | 0/579 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"bfdfc1dd45be4bbfa7594b79342bb463"}},"metadata":{}},{"name":"stdout","text":"train_loss: 0.72810 - val_loss: 1.26275 - train_f1: 0.74881 - val_f1: 0.62772\n\n\nTraining on batches...\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"  0%|          | 0/2313 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"1625bfaecc3746188175a0c4b31b5d56"}},"metadata":{}},{"name":"stdout","text":"Validation on batches...\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"  0%|          | 0/579 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"a24e9e551da14160a863ae757f818e34"}},"metadata":{}},{"name":"stdout","text":"train_loss: 0.38769 - val_loss: 1.38034 - train_f1: 0.86921 - val_f1: 0.63143\n\n","output_type":"stream"}]},{"cell_type":"code","source":"valid_labels, valid_predict, val_loss = validation(valid_dataloader, device)\nreport = classification_report(valid_labels, valid_predict)","metadata":{"execution":{"iopub.status.busy":"2023-11-24T08:25:16.811124Z","iopub.execute_input":"2023-11-24T08:25:16.811412Z","iopub.status.idle":"2023-11-24T08:25:49.533838Z","shell.execute_reply.started":"2023-11-24T08:25:16.811386Z","shell.execute_reply":"2023-11-24T08:25:49.532938Z"},"trusted":true},"execution_count":15,"outputs":[{"output_type":"display_data","data":{"text/plain":"  0%|          | 0/579 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"2df7d9905fa640da9b1e5ddd84b4e26a"}},"metadata":{}},{"name":"stderr","text":"/opt/conda/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n  _warn_prf(average, modifier, msg_start, len(result))\n/opt/conda/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n  _warn_prf(average, modifier, msg_start, len(result))\n/opt/conda/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n  _warn_prf(average, modifier, msg_start, len(result))\n","output_type":"stream"}]},{"cell_type":"code","source":"print(report)","metadata":{"execution":{"iopub.status.busy":"2023-11-24T08:25:49.534984Z","iopub.execute_input":"2023-11-24T08:25:49.535266Z","iopub.status.idle":"2023-11-24T08:25:49.540244Z","shell.execute_reply.started":"2023-11-24T08:25:49.535241Z","shell.execute_reply":"2023-11-24T08:25:49.539277Z"},"trusted":true},"execution_count":16,"outputs":[{"name":"stdout","text":"              precision    recall  f1-score   support\n\n           0       0.00      0.00      0.00         4\n           1       0.65      0.58      0.61       377\n           2       0.68      0.82      0.74       402\n           3       0.69      0.77      0.73        26\n           4       0.67      0.69      0.68       188\n           5       0.87      0.87      0.87       158\n           6       0.61      0.78      0.68        36\n           7       0.86      0.75      0.80        16\n           8       0.00      0.00      0.00        23\n           9       0.89      0.93      0.91       254\n          10       0.00      0.00      0.00        17\n          11       0.00      0.00      0.00        23\n          12       0.95      0.77      0.85        47\n          13       0.74      0.79      0.76        76\n          14       0.57      0.67      0.62       115\n          15       0.84      0.94      0.89        17\n          16       1.00      0.75      0.86         4\n          17       0.66      0.81      0.73        96\n          18       0.50      0.41      0.45        22\n          19       0.75      1.00      0.86         3\n          20       0.20      0.10      0.13        10\n          21       0.74      0.87      0.80        45\n          22       0.44      0.56      0.49       177\n          23       0.00      0.00      0.00         5\n          24       0.46      0.45      0.46        66\n          25       0.67      0.69      0.68        84\n          26       0.33      0.14      0.20        14\n          27       0.41      0.46      0.43        65\n          28       0.50      0.43      0.46         7\n          29       0.64      0.57      0.60       122\n          30       0.50      0.50      0.50         4\n          31       0.28      0.21      0.24        24\n          32       0.64      0.70      0.67        20\n          33       1.00      0.75      0.86         4\n          34       1.00      0.67      0.80         3\n          35       0.92      1.00      0.96        12\n          36       0.33      0.31      0.32        45\n          37       0.50      0.35      0.41        17\n          38       0.24      0.15      0.19        26\n          39       0.00      0.00      0.00         1\n          40       0.74      0.74      0.74        42\n          41       0.64      0.75      0.69        12\n          42       0.55      0.54      0.55        39\n          43       0.60      0.60      0.60        60\n          44       0.85      0.83      0.84       111\n          45       0.73      0.73      0.73        11\n          46       0.67      0.40      0.50         5\n          47       0.71      0.38      0.50        13\n          48       0.45      0.45      0.45        11\n          49       0.70      0.60      0.65        50\n          50       0.47      0.73      0.57        11\n          51       0.46      0.59      0.52        27\n          52       1.00      1.00      1.00        47\n          53       1.00      0.50      0.67         2\n          54       0.53      0.67      0.59        27\n          55       0.25      0.20      0.22         5\n          56       0.28      0.24      0.26        41\n          57       0.42      0.42      0.42        12\n          58       0.75      0.68      0.71        31\n          59       0.56      0.53      0.55        17\n          60       0.80      0.50      0.62         8\n          61       0.76      0.97      0.85        38\n          62       0.33      0.17      0.22         6\n          63       0.74      0.70      0.72        20\n          64       0.67      0.70      0.68        73\n          65       0.44      0.46      0.45        37\n          66       0.33      0.07      0.11        15\n          67       1.00      0.67      0.80         3\n          68       0.88      0.79      0.83        19\n          69       0.33      0.30      0.32        10\n          70       0.29      0.13      0.18        31\n          71       0.60      0.67      0.63        18\n          72       0.65      0.83      0.73       144\n          73       0.71      0.50      0.59        10\n          74       0.00      0.00      0.00         2\n          75       0.50      0.40      0.44        10\n          76       0.54      0.72      0.62        18\n          77       0.62      0.53      0.57        15\n          78       0.85      0.92      0.88        36\n          79       0.40      0.67      0.50         3\n          80       0.79      0.79      0.79        19\n          81       1.00      1.00      1.00        17\n          82       0.55      0.71      0.62        17\n          83       0.87      0.72      0.79        18\n          84       0.00      0.00      0.00         3\n          85       0.00      0.00      0.00         3\n          86       0.70      0.78      0.74        27\n          87       0.71      0.73      0.72        48\n          88       0.62      0.52      0.57        25\n          89       1.00      1.00      1.00         2\n          90       0.75      0.67      0.71         9\n          91       0.77      0.91      0.83        11\n          92       0.50      0.14      0.22         7\n          93       0.82      0.93      0.87        15\n          94       0.50      0.40      0.44        10\n          95       0.56      0.56      0.56         9\n          96       0.00      0.00      0.00         4\n          97       0.47      0.36      0.41        22\n          98       0.58      0.78      0.67         9\n          99       1.00      0.75      0.86         4\n         100       0.25      0.27      0.26        11\n         101       1.00      1.00      1.00         4\n         102       0.00      0.00      0.00         4\n         103       0.25      0.26      0.26        19\n         104       0.00      0.00      0.00         3\n         105       0.50      0.20      0.29         5\n         106       0.90      0.60      0.72        15\n         107       0.00      0.00      0.00         2\n         108       0.70      0.84      0.76        19\n         109       0.00      0.00      0.00         4\n         110       0.00      0.00      0.00         2\n         111       0.79      0.85      0.81        26\n         112       0.00      0.00      0.00         3\n         113       0.50      0.50      0.50        16\n         114       0.13      0.29      0.18         7\n         115       0.33      0.33      0.33         3\n         116       0.82      0.69      0.75        26\n         117       0.83      0.62      0.71         8\n         118       0.00      0.00      0.00         3\n         119       0.00      0.00      0.00         4\n         120       1.00      1.00      1.00         5\n         121       0.00      0.00      0.00         1\n         122       0.33      0.22      0.27         9\n         123       0.88      0.88      0.88         8\n         124       0.50      0.71      0.59         7\n         125       0.29      0.27      0.28        15\n         126       0.53      0.48      0.50        21\n         127       0.89      0.89      0.89         9\n         128       0.00      0.00      0.00         2\n         129       0.50      0.56      0.53         9\n         130       0.42      0.42      0.42        12\n         131       1.00      1.00      1.00         1\n         132       0.00      0.00      0.00         8\n         133       0.81      0.81      0.81        16\n         134       0.46      0.50      0.48        12\n         135       0.00      0.00      0.00         4\n         136       0.00      0.00      0.00         2\n         137       0.83      0.56      0.67        18\n         138       0.50      0.60      0.55         5\n         139       0.50      0.60      0.55         5\n         140       0.67      0.67      0.67         9\n         141       0.33      0.29      0.31         7\n         142       0.00      0.00      0.00         2\n         143       0.71      0.67      0.69        15\n         144       0.92      1.00      0.96        12\n         145       0.80      1.00      0.89         4\n         146       0.75      0.90      0.82        10\n         147       0.57      0.80      0.67         5\n         148       0.60      0.69      0.64        13\n         149       0.50      1.00      0.67         2\n         150       0.00      0.00      0.00         1\n         151       1.00      1.00      1.00         3\n         152       0.30      0.25      0.27        12\n         153       1.00      0.33      0.50         3\n         154       0.00      0.00      0.00         2\n         155       1.00      1.00      1.00         5\n         156       0.27      0.21      0.24        14\n         157       0.71      0.56      0.63         9\n         158       0.00      0.00      0.00         3\n         159       0.00      0.00      0.00         2\n         160       0.00      0.00      0.00         1\n         161       0.00      0.00      0.00         4\n         162       0.33      0.30      0.32        10\n         163       0.50      0.67      0.57         3\n         164       0.33      0.14      0.20         7\n         165       1.00      1.00      1.00         6\n         166       0.50      0.20      0.29        10\n         167       1.00      0.33      0.50         3\n         168       0.00      0.00      0.00         1\n         169       1.00      1.00      1.00         2\n         170       0.00      0.00      0.00         4\n         171       0.86      1.00      0.92         6\n         172       1.00      0.33      0.50         3\n         173       1.00      0.50      0.67         4\n         174       1.00      1.00      1.00         1\n         175       0.11      0.20      0.14         5\n         176       0.00      0.00      0.00         2\n         177       0.17      0.25      0.20         4\n         178       1.00      0.33      0.50         3\n         179       0.00      0.00      0.00         1\n         180       0.67      1.00      0.80         2\n         181       0.00      0.00      0.00         2\n         182       0.00      0.00      0.00         2\n         183       0.00      0.00      0.00         3\n         184       0.00      0.00      0.00         3\n         185       1.00      0.50      0.67         2\n         186       0.00      0.00      0.00         3\n         187       0.60      0.60      0.60         5\n         188       0.00      0.00      0.00         2\n         189       0.00      0.00      0.00         2\n         190       0.00      0.00      0.00         2\n         191       0.00      0.00      0.00         1\n         192       0.00      0.00      0.00         3\n         193       0.00      0.00      0.00         2\n         194       0.00      0.00      0.00         2\n\n    accuracy                           0.65      4626\n   macro avg       0.49      0.47      0.47      4626\nweighted avg       0.63      0.65      0.63      4626\n\n","output_type":"stream"}]},{"cell_type":"markdown","source":"#### Training with augmented data","metadata":{}},{"cell_type":"code","source":"df_aug = pd.read_csv('/kaggle/input/augmented/augmented.csv').sample(frac=1).reset_index()\ndf_aug.head(3)","metadata":{"execution":{"iopub.status.busy":"2023-11-24T08:31:09.435112Z","iopub.execute_input":"2023-11-24T08:31:09.435985Z","iopub.status.idle":"2023-11-24T08:31:09.630679Z","shell.execute_reply.started":"2023-11-24T08:31:09.435949Z","shell.execute_reply":"2023-11-24T08:31:09.629775Z"},"trusted":true},"execution_count":33,"outputs":[{"execution_count":33,"output_type":"execute_result","data":{"text/plain":"   index                                               text  \\\n0   8646  Как можно узнать расписание автобуса и маршрут...   \n1  11581  Врач пульмонолога и его коллега. Вот и боимся,...   \n2  22970  Где найти авторитеты? Им не стыдно, что в горо...   \n\n                 big_labels                                smol_labels  \n0    Общественный транспорт   График движения общественного транспорта  \n1  Здравоохранение/Медицина                  Ошибки врачей, халатность  \n2           Роспотребнадзор  Санитарно-эпидемиологическое благополучие  ","text/html":"<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>index</th>\n      <th>text</th>\n      <th>big_labels</th>\n      <th>smol_labels</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>8646</td>\n      <td>Как можно узнать расписание автобуса и маршрут...</td>\n      <td>Общественный транспорт</td>\n      <td>График движения общественного транспорта</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>11581</td>\n      <td>Врач пульмонолога и его коллега. Вот и боимся,...</td>\n      <td>Здравоохранение/Медицина</td>\n      <td>Ошибки врачей, халатность</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>22970</td>\n      <td>Где найти авторитеты? Им не стыдно, что в горо...</td>\n      <td>Роспотребнадзор</td>\n      <td>Санитарно-эпидемиологическое благополучие</td>\n    </tr>\n  </tbody>\n</table>\n</div>"},"metadata":{}}]},{"cell_type":"code","source":"# renaming columns\ndf_aug[\"text\"] = df_aug[\"big_labels\"] + ': ' + df_aug[\"text\"]\ndf_aug = df_aug[['text', 'smol_labels']]\ndf_aug = df_aug.dropna()\ndf_aug.columns = ['text', 'label']\ndf_aug.head()","metadata":{"execution":{"iopub.status.busy":"2023-11-24T08:31:09.713645Z","iopub.execute_input":"2023-11-24T08:31:09.713973Z","iopub.status.idle":"2023-11-24T08:31:09.747477Z","shell.execute_reply.started":"2023-11-24T08:31:09.713947Z","shell.execute_reply":"2023-11-24T08:31:09.746601Z"},"trusted":true},"execution_count":34,"outputs":[{"execution_count":34,"output_type":"execute_result","data":{"text/plain":"                                                text  \\\n0  Общественный транспорт: Как можно узнать распи...   \n1  Здравоохранение/Медицина: Врач пульмонолога и ...   \n2  Роспотребнадзор: Где найти авторитеты? Им не с...   \n3  Коронавирус: Мне дали второй компонент ревакци...   \n4  Благоустройство: Я хочу рассказать о том, как ...   \n\n                                               label  \n0           График движения общественного транспорта  \n1                          Ошибки врачей, халатность  \n2          Санитарно-эпидемиологическое благополучие  \n3                                 Доступность вакцин  \n4  ★ Нарушение правил уборки от снега и наледи вн...  ","text/html":"<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>text</th>\n      <th>label</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>Общественный транспорт: Как можно узнать распи...</td>\n      <td>График движения общественного транспорта</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>Здравоохранение/Медицина: Врач пульмонолога и ...</td>\n      <td>Ошибки врачей, халатность</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>Роспотребнадзор: Где найти авторитеты? Им не с...</td>\n      <td>Санитарно-эпидемиологическое благополучие</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>Коронавирус: Мне дали второй компонент ревакци...</td>\n      <td>Доступность вакцин</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>Благоустройство: Я хочу рассказать о том, как ...</td>\n      <td>★ Нарушение правил уборки от снега и наледи вн...</td>\n    </tr>\n  </tbody>\n</table>\n</div>"},"metadata":{}}]},{"cell_type":"code","source":"aug_val = pd.DataFrame(data={\n    \"text\": df_aug.text,\n    \"label\": df_aug.label\n})","metadata":{"execution":{"iopub.status.busy":"2023-11-24T08:31:12.628544Z","iopub.execute_input":"2023-11-24T08:31:12.628921Z","iopub.status.idle":"2023-11-24T08:31:12.635067Z","shell.execute_reply.started":"2023-11-24T08:31:12.628891Z","shell.execute_reply":"2023-11-24T08:31:12.634138Z"},"trusted":true},"execution_count":35,"outputs":[]},{"cell_type":"code","source":"print('Dealing with Validation...')\naug_dataset =  MyDataset(df=aug_val, \n                               tokenizer=tokenizer)\nprint('Created `valid_dataset` with %d examples!'%len(aug_dataset))\n\naug_dataloader = DataLoader(aug_dataset, batch_size=batch_size, shuffle=False, collate_fn=gpt2_classificaiton_collator)\nprint('Created `eval_dataloader` with %d batches!'%len(aug_dataset))","metadata":{"execution":{"iopub.status.busy":"2023-11-24T08:31:22.357018Z","iopub.execute_input":"2023-11-24T08:31:22.357377Z","iopub.status.idle":"2023-11-24T08:31:22.364564Z","shell.execute_reply.started":"2023-11-24T08:31:22.357351Z","shell.execute_reply":"2023-11-24T08:31:22.363720Z"},"trusted":true},"execution_count":36,"outputs":[{"name":"stdout","text":"Dealing with Validation...\nCreated `valid_dataset` with 23594 examples!\nCreated `eval_dataloader` with 23594 batches!\n","output_type":"stream"}]},{"cell_type":"code","source":"from sklearn.metrics import classification_report, accuracy_score, f1_score\nfrom transformers import Adafactor\n\noptimizer = Adafactor(model.parameters(),\n                  lr = 2e-3, # default is 5e-5, our notebook had 2e-5\n                  relative_step=False)\n\ntotal_steps = len(train_dataloader) * epochs\n\nscheduler = get_cosine_schedule_with_warmup(optimizer, \n                                            num_warmup_steps = 0, # Default value in run_glue.py\n                                            num_training_steps = total_steps)\nprint('Epoch')\nfor epoch in tqdm(range(epochs)):\n    print()\n    print('Training on batches...')\n\n    train_labels, train_predict, train_loss = train(aug_dataloader, optimizer, scheduler, device)\n    train_f1 = f1_score(train_labels, train_predict, average='weighted')\n\n\n    print('Validation on batches...')\n    valid_labels, valid_predict, val_loss = validation(valid_dataloader, device)\n    val_f1 = f1_score(valid_labels, valid_predict, average='weighted')\n\n    print(\"train_loss: %.5f - val_loss: %.5f - train_f1: %.5f - val_f1: %.5f\"%(train_loss, val_loss, train_f1, val_f1))\n    print()","metadata":{"execution":{"iopub.status.busy":"2023-11-24T08:31:45.980899Z","iopub.execute_input":"2023-11-24T08:31:45.981270Z","iopub.status.idle":"2023-11-24T09:03:51.016776Z","shell.execute_reply.started":"2023-11-24T08:31:45.981240Z","shell.execute_reply":"2023-11-24T09:03:51.015939Z"},"trusted":true},"execution_count":37,"outputs":[{"name":"stdout","text":"Epoch\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"  0%|          | 0/4 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"2b06717e237b404399070930bdec28e3"}},"metadata":{}},{"name":"stdout","text":"\nTraining on batches...\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"  0%|          | 0/2950 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"1e2d1e06839c49ce8ac2cd49c52a8f4b"}},"metadata":{}},{"name":"stdout","text":"Validation on batches...\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"  0%|          | 0/579 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"2e0a8db408c44b28981aac8ee4c6f7cd"}},"metadata":{}},{"name":"stdout","text":"train_loss: 1.24849 - val_loss: 1.07032 - train_f1: 0.60384 - val_f1: 0.63302\n\n\nTraining on batches...\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"  0%|          | 0/2950 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"986d67cedc004c28845ad5a7b5e90a2b"}},"metadata":{}},{"name":"stdout","text":"Validation on batches...\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"  0%|          | 0/579 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"1f0cc0f92bd1434ebac1304f1976bb1f"}},"metadata":{}},{"name":"stdout","text":"train_loss: 0.77093 - val_loss: 0.85364 - train_f1: 0.74519 - val_f1: 0.71778\n\n\nTraining on batches...\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"  0%|          | 0/2950 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"b3b96a16764645fdb161b14283bcb9b8"}},"metadata":{}},{"name":"stdout","text":"Validation on batches...\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"  0%|          | 0/579 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"9d260a1506fe4121980db091af6dda87"}},"metadata":{}},{"name":"stdout","text":"train_loss: 0.36716 - val_loss: 0.89804 - train_f1: 0.88189 - val_f1: 0.73797\n\n\nTraining on batches...\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"  0%|          | 0/2950 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"e6432a69eed9432bbff01c723fef901f"}},"metadata":{}},{"name":"stdout","text":"Validation on batches...\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"  0%|          | 0/579 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"dc564d1b2790435aa33a46f29595da25"}},"metadata":{}},{"name":"stdout","text":"train_loss: 0.24401 - val_loss: 0.92434 - train_f1: 0.92596 - val_f1: 0.73730\n\n","output_type":"stream"}]},{"cell_type":"code","source":"valid_labels, valid_predict, val_loss = validation(valid_dataloader, device)\nreport = classification_report(valid_labels, valid_predict)","metadata":{"execution":{"iopub.status.busy":"2023-11-24T09:15:26.154905Z","iopub.execute_input":"2023-11-24T09:15:26.155302Z","iopub.status.idle":"2023-11-24T09:15:58.872200Z","shell.execute_reply.started":"2023-11-24T09:15:26.155270Z","shell.execute_reply":"2023-11-24T09:15:58.871336Z"},"trusted":true},"execution_count":38,"outputs":[{"output_type":"display_data","data":{"text/plain":"  0%|          | 0/579 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"7962a8b4db0242709c4b4a58300b7af5"}},"metadata":{}},{"name":"stderr","text":"/opt/conda/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n  _warn_prf(average, modifier, msg_start, len(result))\n/opt/conda/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n  _warn_prf(average, modifier, msg_start, len(result))\n/opt/conda/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n  _warn_prf(average, modifier, msg_start, len(result))\n","output_type":"stream"}]},{"cell_type":"code","source":"print(report)","metadata":{"execution":{"iopub.status.busy":"2023-11-24T09:16:01.081925Z","iopub.execute_input":"2023-11-24T09:16:01.082751Z","iopub.status.idle":"2023-11-24T09:16:01.087292Z","shell.execute_reply.started":"2023-11-24T09:16:01.082719Z","shell.execute_reply":"2023-11-24T09:16:01.086366Z"},"trusted":true},"execution_count":39,"outputs":[{"name":"stdout","text":"              precision    recall  f1-score   support\n\n           0       0.75      0.75      0.75         4\n           1       0.75      0.69      0.72       377\n           2       0.74      0.84      0.79       402\n           3       0.78      0.81      0.79        26\n           4       0.72      0.77      0.74       188\n           5       0.92      0.91      0.91       158\n           6       0.74      0.89      0.81        36\n           7       0.85      0.69      0.76        16\n           8       0.38      0.39      0.38        23\n           9       0.89      0.96      0.93       254\n          10       0.27      0.24      0.25        17\n          11       0.20      0.04      0.07        23\n          12       0.93      0.89      0.91        47\n          13       0.87      0.78      0.82        76\n          14       0.70      0.81      0.75       115\n          15       0.76      0.94      0.84        17\n          16       1.00      0.75      0.86         4\n          17       0.72      0.95      0.82        96\n          18       0.79      0.68      0.73        22\n          19       1.00      1.00      1.00         3\n          20       0.60      0.30      0.40        10\n          21       0.83      0.84      0.84        45\n          22       0.60      0.63      0.61       177\n          23       0.50      0.20      0.29         5\n          24       0.68      0.64      0.66        66\n          25       0.72      0.69      0.70        84\n          26       0.83      0.36      0.50        14\n          27       0.67      0.68      0.67        65\n          28       0.80      0.57      0.67         7\n          29       0.72      0.84      0.78       122\n          30       0.75      0.75      0.75         4\n          31       0.53      0.38      0.44        24\n          32       0.61      0.70      0.65        20\n          33       1.00      0.25      0.40         4\n          34       1.00      1.00      1.00         3\n          35       0.92      1.00      0.96        12\n          36       0.56      0.64      0.60        45\n          37       1.00      0.47      0.64        17\n          38       0.67      0.54      0.60        26\n          39       0.00      0.00      0.00         1\n          40       0.82      0.76      0.79        42\n          41       0.71      0.83      0.77        12\n          42       0.76      0.67      0.71        39\n          43       0.70      0.73      0.72        60\n          44       0.80      0.89      0.85       111\n          45       0.83      0.45      0.59        11\n          46       0.75      0.60      0.67         5\n          47       0.64      0.69      0.67        13\n          48       0.86      0.55      0.67        11\n          49       0.69      0.88      0.77        50\n          50       0.82      0.82      0.82        11\n          51       0.69      0.93      0.79        27\n          52       1.00      1.00      1.00        47\n          53       0.67      1.00      0.80         2\n          54       0.82      0.67      0.73        27\n          55       0.67      0.40      0.50         5\n          56       0.71      0.29      0.41        41\n          57       0.53      0.75      0.62        12\n          58       0.79      0.61      0.69        31\n          59       0.75      0.53      0.62        17\n          60       0.70      0.88      0.78         8\n          61       0.76      0.97      0.85        38\n          62       0.50      0.17      0.25         6\n          63       0.85      0.85      0.85        20\n          64       0.82      0.79      0.81        73\n          65       0.60      0.57      0.58        37\n          66       1.00      0.20      0.33        15\n          67       0.75      1.00      0.86         3\n          68       0.89      0.89      0.89        19\n          69       0.58      0.70      0.64        10\n          70       0.69      0.29      0.41        31\n          71       0.62      0.83      0.71        18\n          72       0.76      0.85      0.80       144\n          73       0.67      0.80      0.73        10\n          74       0.67      1.00      0.80         2\n          75       0.40      0.40      0.40        10\n          76       0.70      0.78      0.74        18\n          77       0.83      0.67      0.74        15\n          78       0.92      0.97      0.95        36\n          79       0.40      0.67      0.50         3\n          80       0.94      0.79      0.86        19\n          81       1.00      1.00      1.00        17\n          82       0.83      0.59      0.69        17\n          83       1.00      1.00      1.00        18\n          84       0.33      0.33      0.33         3\n          85       0.33      0.33      0.33         3\n          86       0.79      0.81      0.80        27\n          87       0.74      0.83      0.78        48\n          88       0.79      0.76      0.78        25\n          89       1.00      1.00      1.00         2\n          90       0.75      0.67      0.71         9\n          91       1.00      1.00      1.00        11\n          92       0.50      0.43      0.46         7\n          93       0.79      1.00      0.88        15\n          94       0.70      0.70      0.70        10\n          95       0.50      0.44      0.47         9\n          96       0.33      0.50      0.40         4\n          97       0.65      0.59      0.62        22\n          98       1.00      1.00      1.00         9\n          99       0.40      0.50      0.44         4\n         100       0.45      0.45      0.45        11\n         101       1.00      1.00      1.00         4\n         102       0.00      0.00      0.00         4\n         103       0.67      0.63      0.65        19\n         104       0.00      0.00      0.00         3\n         105       0.80      0.80      0.80         5\n         106       0.86      0.80      0.83        15\n         107       0.00      0.00      0.00         2\n         108       0.85      0.89      0.87        19\n         109       0.75      0.75      0.75         4\n         110       1.00      1.00      1.00         2\n         111       0.82      0.88      0.85        26\n         112       1.00      0.33      0.50         3\n         113       0.64      0.88      0.74        16\n         114       0.38      0.43      0.40         7\n         115       0.75      1.00      0.86         3\n         116       0.95      0.77      0.85        26\n         117       0.80      0.50      0.62         8\n         118       0.67      0.67      0.67         3\n         119       0.00      0.00      0.00         4\n         120       1.00      1.00      1.00         5\n         121       0.00      0.00      0.00         1\n         122       0.56      0.56      0.56         9\n         123       1.00      1.00      1.00         8\n         124       0.62      0.71      0.67         7\n         125       0.29      0.13      0.18        15\n         126       0.75      0.57      0.65        21\n         127       0.90      1.00      0.95         9\n         128       0.50      0.50      0.50         2\n         129       0.55      0.67      0.60         9\n         130       0.70      0.58      0.64        12\n         131       1.00      1.00      1.00         1\n         132       0.33      0.50      0.40         8\n         133       0.71      0.94      0.81        16\n         134       0.54      0.58      0.56        12\n         135       1.00      0.25      0.40         4\n         136       1.00      0.50      0.67         2\n         137       0.74      0.78      0.76        18\n         138       1.00      1.00      1.00         5\n         139       1.00      0.80      0.89         5\n         140       1.00      0.78      0.88         9\n         141       0.67      0.29      0.40         7\n         142       1.00      1.00      1.00         2\n         143       0.86      0.80      0.83        15\n         144       1.00      1.00      1.00        12\n         145       1.00      1.00      1.00         4\n         146       0.80      0.80      0.80        10\n         147       1.00      1.00      1.00         5\n         148       0.80      0.92      0.86        13\n         149       0.67      1.00      0.80         2\n         150       0.00      0.00      0.00         1\n         151       1.00      1.00      1.00         3\n         152       0.58      0.58      0.58        12\n         153       0.00      0.00      0.00         3\n         154       0.00      0.00      0.00         2\n         155       1.00      1.00      1.00         5\n         156       0.33      0.29      0.31        14\n         157       0.83      0.56      0.67         9\n         158       0.00      0.00      0.00         3\n         159       0.00      0.00      0.00         2\n         160       1.00      1.00      1.00         1\n         161       0.50      0.25      0.33         4\n         162       0.50      0.30      0.37        10\n         163       1.00      0.67      0.80         3\n         164       1.00      0.14      0.25         7\n         165       1.00      0.83      0.91         6\n         166       1.00      0.30      0.46        10\n         167       1.00      0.33      0.50         3\n         168       0.50      1.00      0.67         1\n         169       1.00      1.00      1.00         2\n         170       0.00      0.00      0.00         4\n         171       0.86      1.00      0.92         6\n         172       1.00      1.00      1.00         3\n         173       1.00      0.50      0.67         4\n         174       1.00      1.00      1.00         1\n         175       1.00      0.20      0.33         5\n         176       0.33      0.50      0.40         2\n         177       0.50      0.25      0.33         4\n         178       1.00      0.67      0.80         3\n         179       0.25      1.00      0.40         1\n         180       1.00      1.00      1.00         2\n         181       1.00      0.50      0.67         2\n         182       0.50      0.50      0.50         2\n         183       0.00      0.00      0.00         3\n         184       0.00      0.00      0.00         3\n         185       1.00      0.50      0.67         2\n         186       1.00      0.33      0.50         3\n         187       0.80      0.80      0.80         5\n         188       0.50      0.50      0.50         2\n         189       0.00      0.00      0.00         2\n         190       0.00      0.00      0.00         2\n         191       0.00      0.00      0.00         1\n         192       0.25      0.33      0.29         3\n         193       1.00      0.50      0.67         2\n         194       0.00      0.00      0.00         2\n\n    accuracy                           0.75      4626\n   macro avg       0.69      0.63      0.63      4626\nweighted avg       0.75      0.75      0.74      4626\n\n","output_type":"stream"}]},{"cell_type":"markdown","source":"Due to the augmentation data there is can be a leak in the validation part (because we augmented all data and trained with it). Later we checked F1-score with the correct validation and the actual score was about 0.7","metadata":{}},{"cell_type":"markdown","source":"### Saving model's weights","metadata":{}},{"cell_type":"code","source":"torch.save(model.state_dict(), f\"rugpt_small_labels_74.pt\")","metadata":{"execution":{"iopub.status.busy":"2023-11-24T09:23:25.831853Z","iopub.execute_input":"2023-11-24T09:23:25.832397Z","iopub.status.idle":"2023-11-24T09:23:26.551076Z","shell.execute_reply.started":"2023-11-24T09:23:25.832366Z","shell.execute_reply":"2023-11-24T09:23:26.550267Z"},"trusted":true},"execution_count":49,"outputs":[]},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]}]}